import discord
from discord.ext import commands
import nest_asyncio
from openai import OpenAI

# Apply nest_asyncio to handle event loop issues in Jupyter Notebooks
nest_asyncio.apply()

# Discord bot token
TOKEN = '<YOUR_DISCORD_TOKEN>'

# LLaMA API key
LLAMA_API_KEY = '<YOUR_LLAMA_API_KEY>'

# Initialize the OpenAI client for LLaMA API
client = OpenAI(
    api_key=LLAMA_API_KEY,
    base_url="https://api.llama-api.com"
)

# Define intents
intents = discord.Intents.default()
intents.message_content = True  # Enable the message content intent

# Initialize the bot with a command prefix and intents
bot = commands.Bot(command_prefix='!', intents=intents)

# Specify the allowed server (guild) ID and channel ID
ALLOWED_SERVER_ID = <YOUR_SERVER_ID>
ALLOWED_CHANNEL_ID = <YOUR_CHANNEL_ID>

@bot.event
async def on_ready():
    print(f'We have logged in as {bot.user}')

@bot.command()
async def ask(ctx, *, question: str):
    # Check if the command is used in the allowed server and channel
    if ctx.guild.id != ALLOWED_SERVER_ID:
        await ctx.send("This command can only be used in the specified server.")
        return

    if ctx.channel.id != ALLOWED_CHANNEL_ID:
        await ctx.send("This command can only be used in <YOUR_CHANNEL_LINK>.")
        return

    # Define the prompt for the LLaMA model
    prompt = f"Q: {question}\nA:"

    # Make a request to the LLaMA API
    response = client.chat.completions.create(
        model="llama-7b-chat",  # Adjust model name if necessary. The defaul is 7b, there are two more.
        messages=[
            {"role": "system", "content": "Assistant is a large language model trained by OpenAI."},
            {"role": "user", "content": prompt}
        ]
    )

    # Extract and print the generated response
    generated_text = response.choices[0].message.content.strip()

    # Send the response back to the Discord channel
    await ctx.send(generated_text)

# Run the bot
bot.run(TOKEN)
