import discord
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import asyncio

# Set up the Discord client
intents = discord.Intents.default()
intents.message_content = True
client = discord.Client(intents=intents)

# Load pre-trained model and tokenizer
model_name = "microsoft/DialoGPT-medium"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Source code link
source_code_link = "-# [Source Code - GitHub](<https://github.com/FlameF0X/COL-project>)" # DO NOT REMOVE THIS, I DESERVE ALL THE CREDIT TO IT BECAUSE I MADE IT!

# Function to generate a response
def generate_response(input_text, chat_history_ids=None):
    new_user_input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors='pt')
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if chat_history_ids is not None else new_user_input_ids
    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)
    chat_output = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)
    return f"{chat_output}\n\n{source_code_link}", chat_history_ids

# Handle messages
@client.event
async def on_ready():
    print(f'Logged in as {client.user}')

@client.event
async def on_message(message):
    if message.author == client.user:
        return

    if message.content.lower().startswith('!chat'):
        user_input = message.content[5:].strip()
        response, chat_history_ids = generate_response(user_input)
        await message.channel.send(response)

# Function to run the bot
async def run_bot():
    await client.start('YOUR_DISCORD_BOT_TOKEN')  # Replace with your actual bot token

# Run the bot in an asynchronous event loop
async def main():
    await run_bot()

# Run the bot in the notebook's event loop
import nest_asyncio
nest_asyncio.apply()
loop = asyncio.get_event_loop()
loop.run_until_complete(main())
